✅ Inkphora Gesture-Based Emotional Embedding (Public Overview)

This repository presents the public conceptual overview of the Inkphora/Thymiko emotional inference model based on freehand touchscreen strokes.

The system maps raw gesture features to a Valence–Arousal emotional embedding, which can condition creative AI outputs, adaptive interfaces, and emotional recommendation systems.

This repository contains:

public documentation (PDF)

conceptual architecture

sample diagrams

lightweight demo references

Code implementations remain private for security and research reasons.

Core Concepts

Anonymous, non-biometric gesture input

Stroke Feature Vector (SFV) extraction

Emotional inference (Valence–Arousal)

Creative output (text, music, visual adaptation)

API-oriented modular design

Public Documentation

See:
docs/Inkphora_Gesture_Embedding_Public_Disclosure.pdf

This document establishes the conceptual priority and authorship of the method.

Demo

A minimal public demo is hosted on Hugging Face Spaces under the same author identity.

Author
Maria Irene Marchetti
(aka Miren / Thymiko-Inkphora Project https://huggingface.co/spaces/Miren-12/thymiko-inkphora-mvp)

Inkphora Project
inkphora.ai